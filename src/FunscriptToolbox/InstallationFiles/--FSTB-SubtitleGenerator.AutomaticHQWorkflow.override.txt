{
  "Workers": [
    // -----------------------------
    // Audio extraction
    {
      "Id": "audio",
      "Enabled": true
    },
    {
      "Id": "audio-clean-waveform",
      "Enabled": true
    },
    {
      "Id": "asig",
      "Enabled": true
    },
    // -----------------------------
    // Creating initial manual-input source 
    {
      "Id": "full-ai",
      "Enabled": true,
      "MaxChunkDuration": "00:03:00",
      "ExportMetadataSrt": false,
      "TranscriptionToIgnorePatterns" : [ 
        { "Name": "A-Moans", "Pattern": "[あぁーっ、。\\s…!！]+" },
        { "Name": "N-Hums", "Pattern": "[んっー、。\\s…!！]+" },
        { "Name": "U-Grunts", "Pattern": "[うぅーっ、。\\s…!！]+" },
        { "Name": "Breathing", "Pattern": "[はぁーっ、。\\s…!！]+" },
        { "Name": "Giggle", "Pattern": "ふふ[っ]*[。！？]*" },
        { "Name": "CombinedFiller", "Pattern": "[あぁうぅんっーは、。\\s…!！]+" }
      ]
    },
    {
      "Id": "full-ai_google",
      "Enabled": true
    },
    {
      "Id": "full",
      "Enabled": true,
      "SourceId": "full-ai"
    },
    {
      "Id": "generated-manual-input-srt",
      "Enabled": true,
      // [OPTION] Change to "full" if you prefer having original text instead of a basic english translation in the the manual-input file.
      "WorkerId": "full-ai_google"
    },
    {
      "Id": "manual-input",
      "Enabled": true
    },
    // -----------------------------
    // AutomaticHQWorkflow: Finalizing timings and voice-texts sources
    {
      "Id": "timings",
      "Enabled": true
    },
    {
      "Id": "on-screen-texts",
      "Enabled": true
    },
    {
      "Id": "speakers",
      "Enabled": false
    },
    {
      "Id": "singlevad-ai-refined",
      // This AI will receive the audio and validate that the transcription by looking at the initial transcription and the full-ai transcription. It also receive and analyze screenshot to create a better TranslationAnalysis.
      // [OPTION] Disable if you want to reduce the API cost.
      "Enabled": true,
      "ExportMetadataSrt": false,
      // Expand the audio send to the AI because we can't trust 100% the automatic timings.
      "ExpandStart": "00:00:01",
      "ExpandEnd": "00:00:01",
      "Options": {
        "MetadataNeeded": "full-VoiceText,!SkipRefined",
        "BinaryDataExtractors": [
          {
            "OutputFieldName": "Screenshot",
            // [OPTION] Set AddContextNodes to 'false' to reduce the size of requests, or increase the Gap settings to have less nodes added. 
            // Short explanation, if there is a large gap between two subtitles, the following context nodes will be added: 
            //    <previous>.EndTime + <ContextShortGap>, ...images every <ContextLongGap>..., <current>.Start Time - <ContextShortGap>.
            "Enabled": true,
            "AddContextNodes": true,
            "ContextShortGap": "00:00:05",
            "ContextLongGap": "00:00:30"
          }
        ],
        // [OPTION] Increase the batch size to reduce the number of request but it also mean that there will be less 'thinking' time allocated per node.
        "BatchSize": 16,
        "BatchSplitWindows": 2,
        "NbContextItems": 15,
        "NbItemsMinimumReceivedToContinue": 1,
        "TextAfterAnalysis": "IMPORTANT: You will only receive the 'full-VoiceText'. The timings on those transcriptions cannot be trusted 100% so the the audio clip you will receive has been padded on each side by 1 second. Try to find the original VoiceText inside the audio clip and only re-analyze that part to see if there was some mistake done in the transcription. If you can't find it, just use the original full-VoiceText."
      }
    },
    {
      "Id": "voice-texts",
      "Enabled": true,
      "SourceId": "full"
    },    
    // -----------------------------
    // Advanced step: Allowing the user to review and override AI generated metadatas
    {
      "Id": "metadatas-srt",
      "Enabled": true
    },
    {
      "Id": "metadatas-review",
      "Enabled": false
      // [OPTION] Set to true if you want to review the metadatas generated by the AI.
    },
        
    // -----------------------------
    // Use timings, manual-input, voice-texts and AI generated metadatas to AI Translation & Arbitration
    {
      "Id": "translated-texts_maverick",
      "Enabled": true,
      "ExportMetadataSrt": false,
      "Options": {
        "BatchSize": 50,
        "BatchSplitWindows": 5,
        "NbContextItems": 10000,
        "NbItemsMinimumReceivedToContinue": 30
      }
    },
    {
      "Id": "finalized_maverick",
      "Enabled": true,
      "ExportMetadataSrt": false,
      "MaxLineLength": 50,
      "MaxMergeGapSameSpeaker": "00:00:01",
      "MaxMergeGapDialogue": "00:00:00.8",
      "MaxMergeDuration": "00:00:04",
      "RemoveMissing": false,
      "AddReviewIfTooLong": true,
      "SplitPatterns": [
        // 1. Strong Punctuation (End of sentence)
        { "CutWhere": "After", "Pattern": "(?<!\\.)\\.(?![\\d\\.])|[?!…]+" },
        // 2. Weak Punctuation (Commas, colons)
        { "CutWhere": "After", "Pattern": "\\.{3}|[,:：]+" },
        // 3. Logical/Casual Connectors (High quality splits)
        { "CutWhere": "Before", "Pattern": "\\b(because|if|since|while|although|until|unless|so|that)\\b" },
        // 4. "Wh-" Clause Connectors (Medium quality splits)
        { "CutWhere": "Before", "Pattern": "\\b(what|when|where|how|why)\\b" },
        // 5. Prepositions (Fallback for long sentences)
        { "CutWhere": "Before", "Pattern": "\\b(with|about|for|from|into)\\b" },
        // 6. Last Resort: Split on any space
        { "CutWhere": "Before", "Pattern": "\\s" }
      ]
    },
    {
      "TranscriptionId": "final-ai-texts",
      "Enabled": true,
      // [OPTION] Set to "arbitrer-final-choice" if you want to go with multiples translation and an arbiter.
      "SourceId": "finalized_maverick"
    },
    {
      "Id": "final-ai-srt",
      "Enabled": true
    },
    {
      "Id": "final-ai-debug-srt",
      "Enabled": true
    },
    {
      "Id": "costs",
      "Enabled": true
    },
    {
      "TranscriptionId": "final-user-texts",
      // [OPTION] Set to true if you want to go import ".final-user.srt" file (final version after manual edit).
      "Enabled": false
    },
    {
      "OutputId": "learning-srt",
      // [OPTION] Set to true if you want to go import ".final-user.srt" file (final version after manual edit) and output a subtitle that, maybe, could be used to help an AI learn your preference.
      "Enabled": false
    },
  ]
}
